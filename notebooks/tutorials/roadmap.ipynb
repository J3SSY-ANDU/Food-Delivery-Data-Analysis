{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa3f5be",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 12-Week Data Science Roadmap\n",
    "\n",
    "| **Week** | **Focus Area** | **Key Topics & Tools** | **Data Science Methodology & Why It's Important** |\n",
    "|----------|----------------|------------------------|--------------------------------------------------|\n",
    "| **Week 1-2** | **Data Manipulation and Exploration** | **Tools**: Pandas, NumPy, Matplotlib <br> **Topics**: Data cleaning, handling missing data, merging datasets, basic EDA (Exploratory Data Analysis) | **Methodology**: **Data Cleaning & Preprocessing** <br> **Why It's Important**: Data cleaning is the most crucial step in any data analysis. Raw data is often messy, containing missing values, errors, or inconsistencies. Cleaning data ensures accuracy and reliability for future analysis or modeling. |\n",
    "| **Week 3-4** | **Data Visualization & Communication** | **Tools**: Seaborn, Plotly, Matplotlib <br> **Topics**: Visualizations (line plots, bar plots, histograms, box plots, pair plots, scatter plots), Creating dashboards | **Methodology**: **Exploratory Data Analysis (EDA)** <br> **Why It's Important**: EDA helps understand the structure and patterns in the data. Effective visualization communicates insights clearly, helping stakeholders make informed decisions. Visualization is essential for recognizing trends, detecting outliers, and comparing variables. |\n",
    "| **Week 5-6** | **Statistical Analysis** | **Tools**: SciPy, Statsmodels, Pandas <br> **Topics**: Descriptive statistics, probability distributions, hypothesis testing, p-values, t-tests, ANOVA | **Methodology**: **Statistical Analysis** <br> **Why It's Important**: Statistical analysis enables you to derive conclusions from your data, make predictions, and test hypotheses. Understanding these methods is vital for making data-driven decisions and validating insights statistically. |\n",
    "| **Week 7-8** | **Supervised Learning: Regression** | **Tools**: Scikit-learn <br> **Topics**: Linear regression, multiple regression, model evaluation (R², MSE, MAE) | **Methodology**: **Supervised Learning** <br> **Why It's Important**: Regression models predict continuous values (e.g., prices, sales). Mastering regression will help you predict numeric outcomes based on input data, which is crucial for tasks such as predicting future trends or customer behavior. |\n",
    "| **Week 9-10** | **Supervised Learning: Classification** | **Tools**: Scikit-learn <br> **Topics**: Logistic regression, KNN, SVM, Random Forest, model evaluation (accuracy, precision, recall, F1-score) | **Methodology**: **Supervised Learning** <br> **Why It's Important**: Classification algorithms are used to assign categories to data points (e.g., email spam detection, disease classification). Learning these techniques allows you to create systems that automatically classify data into predefined groups. |\n",
    "| **Week 11** | **Unsupervised Learning: Clustering** | **Tools**: Scikit-learn, Seaborn <br> **Topics**: K-means, DBSCAN, Hierarchical Clustering, PCA for dimensionality reduction | **Methodology**: **Unsupervised Learning** <br> **Why It's Important**: Unsupervised learning is used when there is no labeled data. Clustering helps group similar data points, and dimensionality reduction (e.g., PCA) reduces complexity. This is important for segmenting data and discovering hidden patterns. |\n",
    "| **Week 12** | **Capstone Project & Portfolio** | **Tools**: Pandas, Scikit-learn, Seaborn, Matplotlib, Jupyter Notebooks <br> **Topics**: Combine all skills learned into a final project (e.g., predicting house prices, customer churn, etc.), build your data science portfolio | **Methodology**: **Project Building & Communication** <br> **Why It's Important**: The final project allows you to showcase all your skills. Building a strong portfolio helps you demonstrate your ability to solve real-world problems and is essential when applying for data science roles. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581d4df1",
   "metadata": {},
   "source": [
    "# Explanation of the 12-Week Data Science Roadmap\n",
    "\n",
    "## **Focus Area**:\n",
    "Each week focuses on a critical skill or concept that is fundamental to data science. This approach ensures you are learning the necessary skills to build a solid foundation in the field.\n",
    "\n",
    "## **Key Topics & Tools**:\n",
    "Each week’s section includes the **tools** (e.g., libraries) and the **topics** you will be learning. These tools are the core libraries commonly used in data science. You’ll be working with libraries like **Pandas**, **NumPy**, **Seaborn**, and **Scikit-learn** that help with tasks like data manipulation, statistical analysis, and machine learning.\n",
    "\n",
    "## **Data Science Methodology**:\n",
    "Each week’s section includes the **data science methodology** that aligns with the topics. Understanding these methodologies will help you learn how to approach and solve real-world problems. It explains **why** each methodology is important in data science, and how it helps you make data-driven decisions, build models, and communicate insights effectively.\n",
    "\n",
    "---\n",
    "\n",
    "# **Overall Structure**\n",
    "\n",
    "1. **Weeks 1-2: Data Manipulation and Exploration**:\n",
    "   - Master the basics of **data manipulation** with **Pandas** and **NumPy**.\n",
    "   - You will learn how to **clean**, **manipulate**, and **explore** datasets before diving into advanced techniques.\n",
    "   - These skills are fundamental because data often comes in an unclean format, and understanding how to handle it efficiently is critical for any data analysis task.\n",
    "\n",
    "2. **Weeks 3-4: Data Visualization & Communication**:\n",
    "   - Learn how to create **meaningful visualizations** using **Seaborn**, **Plotly**, and **Matplotlib**.\n",
    "   - **Data visualization** is essential for making your findings understandable and actionable for stakeholders.\n",
    "   - Effective communication of insights is a key part of data science, and these skills will help you present data in a digestible format.\n",
    "\n",
    "3. **Weeks 5-6: Statistical Analysis**:\n",
    "   - Learn the basics of **statistical methods**, including hypothesis testing, descriptive statistics, and probability.\n",
    "   - **Statistical analysis** ensures that the results and insights you derive from the data are valid and reliable.\n",
    "   - Understanding these techniques is essential for evaluating the significance of your findings.\n",
    "\n",
    "4. **Weeks 7-8: Supervised Learning - Regression**:\n",
    "   - Learn how to use **regression models** to predict **continuous values** (e.g., predicting house prices, sales).\n",
    "   - Mastering **supervised learning** methods like regression is crucial for solving many real-world problems, such as forecasting and trend prediction.\n",
    "\n",
    "5. **Weeks 9-10: Supervised Learning - Classification**:\n",
    "   - Study **classification models** that predict categorical outcomes (e.g., whether a customer will churn, detecting spam).\n",
    "   - You'll also learn how to evaluate classification models using performance metrics like **accuracy**, **precision**, and **recall**.\n",
    "   - Classification is one of the most commonly used techniques in data science for decision-making problems.\n",
    "\n",
    "6. **Week 11: Unsupervised Learning - Clustering**:\n",
    "   - Learn **clustering algorithms** like **K-means** and **DBSCAN**.\n",
    "   - These techniques are used to find patterns and group similar data points without needing labels.\n",
    "   - **Unsupervised learning** is important for exploratory data analysis and discovering hidden structures in data.\n",
    "\n",
    "7. **Week 12: Capstone Project & Portfolio**:\n",
    "   - Build a **capstone project** that incorporates everything you've learned, from data cleaning to machine learning.\n",
    "   - Create a **portfolio** to showcase your projects, which is essential when applying for jobs.\n",
    "   - The final project ties together your skills, allowing you to demonstrate your ability to solve a real-world data problem and communicate your findings clearly.\n",
    "\n",
    "---\n",
    "\n",
    "By following this roadmap, you’ll gradually move from foundational knowledge (data manipulation and cleaning) to advanced techniques (machine learning and clustering). The final weeks are focused on solidifying everything through **real-world applications**, where you'll get hands-on experience with **projects** and **portfolios** to help you transition into the data science job market.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e8d46c",
   "metadata": {},
   "source": [
    "# Weeks 1-2: Data Manipulation and Exploration Projects\n",
    "\n",
    "## **Project 1: Food Delivery Orders EDA**\n",
    "**Objective**: Explore the **food delivery orders dataset** and perform basic analysis on customer orders, cuisine types, and cost of orders.\n",
    "\n",
    "**Dataset**: [Food Ordering and Delivery App Dataset](https://www.kaggle.com/datasets/ahsan81/food-ordering-and-delivery-app-dataset)\n",
    "\n",
    "### **Steps to Follow**:\n",
    "\n",
    "1. **Data Cleaning**:\n",
    "   - Handle missing or incorrect values (if any).\n",
    "   - Check for any **duplicates** in the dataset and remove them if necessary.\n",
    "\n",
    "2. **Exploratory Data Analysis**:\n",
    "   - **General statistics**: Calculate basic statistics like **mean**, **median**, **standard deviation** for columns like **cost_of_the_order** and **food_preparation_time**.\n",
    "   - **Count unique values**: Check for unique values in categorical columns like **cuisine_type** and **day_of_the_week**.\n",
    "   - **Distribution of numerical variables**: Use histograms to check the distribution of **food_preparation_time**, **delivery_time**, and **cost_of_the_order**.\n",
    "   - **Correlation**: Use **correlation matrices** to identify any relationships between numerical variables (e.g., **food_preparation_time** vs **delivery_time**).\n",
    "\n",
    "3. **Data Visualization**:\n",
    "   - Plot the distribution of **order costs** over time or by **cuisine_type** using bar plots or box plots.\n",
    "   - Create a **pie chart** of the most common **cuisine types** or **day of the week** for food deliveries.\n",
    "   - Use a **scatter plot** to visualize the relationship between **food_preparation_time** and **delivery_time**.\n",
    "\n",
    "4. **Insights**:\n",
    "   - Identify the **top-selling cuisines** based on the **cost_of_the_order** or **number of orders**.\n",
    "   - Find the **average order cost** for each **day of the week**.\n",
    "   - Understand the **relationship between delivery time and food preparation time**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Project 2: Delivery Time Analysis and Optimization**\n",
    "**Objective**: Analyze delivery times and understand the factors affecting delivery efficiency (e.g., weather conditions, road traffic, and vehicle condition).\n",
    "\n",
    "**Dataset**: [Food Delivery Dataset](https://www.kaggle.com/datasets/gauravmalik26/food-delivery-dataset)\n",
    "\n",
    "### **Steps to Follow**:\n",
    "\n",
    "1. **Data Cleaning**:\n",
    "   - Handle missing or inconsistent values in columns like **Weatherconditions**, **Road_traffic_density**, and **Vehicle_condition**.\n",
    "   - Convert **Order_Date**, **Time_Orderd**, and **Time_Order_picked** to appropriate **datetime** formats for easier analysis.\n",
    "\n",
    "2. **Exploratory Data Analysis**:\n",
    "   - Calculate **time differences** between **Time_Orderd** and **Time_Order_picked** to understand the **total delivery time**.\n",
    "   - Explore the relationship between **vehicle condition** and **delivery time**. Does a better vehicle condition lead to faster deliveries?\n",
    "   - Analyze how **weather conditions** and **road traffic density** impact delivery times.\n",
    "\n",
    "3. **Data Visualization**:\n",
    "   - Create a **scatter plot** showing the relationship between **vehicle condition** and **delivery time**.\n",
    "   - Use **bar plots** to compare average **delivery times** by **weather conditions** and **road traffic density**.\n",
    "   - Visualize how **order volume** varies by **delivery time** during different **weather conditions** or **road traffic density**.\n",
    "\n",
    "4. **Insights**:\n",
    "   - Identify any **patterns** or **outliers** in delivery times based on **weather** and **traffic conditions**.\n",
    "   - Determine if certain **conditions (e.g., heavy traffic)** lead to higher **delivery time** delays.\n",
    "   - Suggest ways to **optimize delivery times** by improving vehicle conditions or adjusting for traffic/weather issues.\n",
    "\n",
    "---\n",
    "\n",
    "## **Project 3 (Optional): Analyzing Movie Production Budgets vs. Revenues**\n",
    "**Objective**: Visualize and analyze the relationship between movie production budget and revenue across different genres.\n",
    "\n",
    "**Dataset**: [TMDB Movie Metadata](https://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata/data)\n",
    "\n",
    "#### **Steps to Follow**:\n",
    "\n",
    "1. **Data Cleaning**:\n",
    "   - Handle missing values in **budget** and **revenue** columns.\n",
    "   - Remove or fix any erroneous **negative budget** or **revenue** values.\n",
    "\n",
    "2. **Data Manipulation**:\n",
    "   - Convert **budget** and **revenue** to numerical values and handle any **currency symbols** (e.g., USD).\n",
    "   - Group movies by **genre** and calculate **average budget** and **revenue**.\n",
    "\n",
    "3. **Data Visualization**:\n",
    "   - **Bubble Chart**: Visualize **budget** vs. **revenue** for each movie, with the size of the bubble representing the **movie's rating**.\n",
    "   - **Violin Plot**: Show the distribution of **budget** and **revenue** across different **genres**.\n",
    "   - **Scatter Plot**: Plot the relationship between **budget** and **revenue**, and apply a **linear regression** line to explore correlations.\n",
    "\n",
    "4. **Insights**:\n",
    "   - **Budget vs. Revenue**: Explore how a larger **budget** typically correlates with a higher **revenue**, and whether high-budget movies tend to perform better or if there are exceptions.\n",
    "   - **Genre's Impact on Revenue**: Determine which **genres** have higher average revenues and how production costs vary by genre.\n",
    "   - **Investment Efficiency**: Identify which genres or directors consistently produce successful movies with a **low budget** but high **revenue**.\n",
    "   - **Director/Production Influence**: Investigate if movies with certain **directors** or **production companies** are more successful regardless of the budget.\n",
    "   - **Outliers**: Detect any **outliers**—movies with high budgets but low revenues or vice versa—and investigate their causes (e.g., poor marketing, low audience interest, or critical reception).\n",
    "\n",
    "---\n",
    "\n",
    "### **Tools You'll Use**:\n",
    "- **Pandas** (for data cleaning and manipulation)\n",
    "- **Matplotlib** (for basic plots and visualization)\n",
    "- **Seaborn** (for enhanced visualization, such as violin plots and regression lines)\n",
    "\n",
    "---\n",
    "\n",
    "### **Why These Projects Are Important**:\n",
    "- **Data Cleaning**: You'll practice cleaning and preparing data for analysis, which is a key skill in any data science project.\n",
    "- **Exploratory Data Analysis (EDA)**: EDA helps you identify patterns and trends in your data, which will form the foundation of any future modeling.\n",
    "- **Visualization**: Creating visualizations helps in communicating insights from the data clearly, making it easier for stakeholders to make informed decisions.\n",
    "- **Real-World Application**: These projects involve **real-world datasets** that simulate practical challenges faced by businesses in the food delivery industry. They give you hands-on experience working with industry-specific data.\n",
    "\n",
    "---\n",
    "\n",
    "By completing these projects, you'll gain a solid understanding of **data manipulation**, **EDA**, and **visualization**, laying the groundwork for more advanced topics in data science.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
